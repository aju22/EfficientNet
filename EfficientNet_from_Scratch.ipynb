{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet from Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKvqbLAmlE66OckPmMI+eY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aju22/EfficientNet/blob/main/EfficientNet_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EX3IvxqRVny3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "v7Gh1axnE60y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNet is a convolutional neural network architecture and scaling method that uniformly scales all dimensions of depth/width/resolution using a compound coefficient. Unlike conventional practice that arbitrary scales these factors, the EfficientNet scaling method uniformly scales network width, depth, and resolution with a set of fixed scaling coefficients\n",
        "\n",
        "![](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-06_at_10.45.54_PM.png)"
      ],
      "metadata": {
        "id": "u-q2-7WoF-_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = [\n",
        "    # expand_ratio, channels, repeats, stride, kernel_size\n",
        "    [1, 16, 1, 1, 3],\n",
        "    [6, 24, 2, 2, 3],\n",
        "    [6, 40, 2, 2, 5],\n",
        "    [6, 80, 3, 2, 3],\n",
        "    [6, 112, 3, 1, 5],\n",
        "    [6, 192, 4, 2, 5],\n",
        "    [6, 320, 1, 1, 3],\n",
        "]\n",
        "\n",
        "phi_values = {\n",
        "    # tuple of: (phi_value, resolution, drop_rate)\n",
        "    \"b0\": (0, 224, 0.2),  # alpha, beta, gamma, depth = alpha ** phi\n",
        "    \"b1\": (0.5, 240, 0.2),\n",
        "    \"b2\": (1, 260, 0.3),\n",
        "    \"b3\": (2, 300, 0.3),\n",
        "    \"b4\": (3, 380, 0.4),\n",
        "    \"b5\": (4, 456, 0.4),\n",
        "    \"b6\": (5, 528, 0.5),\n",
        "    \"b7\": (6, 600, 0.5),\n",
        "}"
      ],
      "metadata": {
        "id": "jr9nT0gbuuTB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(layers.Layer):\n",
        "  def __init__(self, out_channels, groups = 1, **kwargs):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv = layers.Conv2D(out_channels, use_bias = False, groups = groups, **kwargs)\n",
        "    self.bn = layers.BatchNormalization()\n",
        "    self.silu = layers.Activation(tf.nn.silu)\n",
        "\n",
        "  def call(self, x, training = False):\n",
        "    \n",
        "    x = self.conv(x, training = training)\n",
        "    x = self.bn(x)\n",
        "    x = self.silu(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "vfsoqWW3u0ag"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Squeeze-Excitation Mechanism\n",
        "\n",
        "With the squeeze-and-excitation block, the neural nets are better able to map the channel dependency along with access to global information. Therefore, they are better able to recalibrate the filter outputs and thus, this leads to performance gains.\n",
        "\n",
        "![](https://i.ytimg.com/vi/FUiUfD7bdqw/maxresdefault.jpg)"
      ],
      "metadata": {
        "id": "ij8Ysn3LGNrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SqueezeExcitation(layers.Layer):\n",
        "  def __init__(self, in_channels, reduced_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.SE = tf.keras.Sequential([   \n",
        "                                      layers.GlobalAveragePooling2D(data_format='channels_last', keepdims = True),\n",
        "                                      layers.Conv2D(reduced_dim, kernel_size= 1, padding ='same'),\n",
        "                                      layers.Activation(tf.nn.silu),\n",
        "                                      layers.Conv2D(in_channels, kernel_size= 1, padding = 'same'),\n",
        "                                      layers.Activation(tf.keras.activations.sigmoid)\n",
        "                                  ])\n",
        "    \n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    return x * self.SE(x)    "
      ],
      "metadata": {
        "id": "RpUVPmhkweF3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inverted Residual Blocks\n",
        "\n",
        "An Inverted Residual Block, sometimes called an MBConv Block, is a type of residual block used for image models that uses an inverted structure for efficiency reasons. It was originally proposed for the MobileNetV2 CNN architecture. It has since been reused for several mobile-optimized CNNs.\n",
        "\n",
        "![](https://miro.medium.com/max/571/1*hq62bMEMgvBgU_f8cW7jbw.png)"
      ],
      "metadata": {
        "id": "68ptAy2_HZ_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InvertedResidualBlock(layers.Layer):\n",
        "  def __init__(self, in_channels, out_channels, expand_ratio, **kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.survival_prob = 0.8 #survival_prob\n",
        "    self.use_residual = ((in_channels == out_channels) and (kwargs['strides'] == 1))\n",
        "    \n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.strides = kwargs['strides']\n",
        "\n",
        "\n",
        "    hidden_dim = in_channels*expand_ratio\n",
        "\n",
        "    reduced_dim = int(in_channels / 4) #reduction\n",
        "\n",
        "    self.conv = tf.keras.Sequential([\n",
        "                                     CNNBlock(hidden_dim, groups = hidden_dim, **kwargs),\n",
        "                                     SqueezeExcitation(hidden_dim, reduced_dim),\n",
        "                                     layers.Conv2D(out_channels, strides = 1, kernel_size = 1, padding='same', use_bias = False),\n",
        "                                     layers.BatchNormalization()                                    \n",
        "                                    ])\n",
        "    \n",
        "\n",
        "\n",
        "  def stochastic_depth(self, x, training):\n",
        "    \n",
        "    if not training:\n",
        "      return x\n",
        "\n",
        "    binary_tensor = tf.where((tf.random.uniform((x.shape[0], 1, 1, 1)) < self.survival_prob), 0, 1)\n",
        "    return x * binary_tensor\n",
        "\n",
        "  def call(self, x, training = False):\n",
        "\n",
        "    if self.use_residual:\n",
        "\n",
        "      return self.stochastic_depth(self.conv(x), training = training) + x\n",
        "    \n",
        "    else:\n",
        "\n",
        "      return self.conv(x)"
      ],
      "metadata": {
        "id": "vChdUEi51hX2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNet(tf.keras.Model):\n",
        "  def __init__(self, version, num_classes):\n",
        "\n",
        "    super().__init__()\n",
        "    width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\n",
        "    last_channels = math.ceil(1280*width_factor)\n",
        "    self.features = self.create_features(width_factor, depth_factor, last_channels)\n",
        "\n",
        "    self.pool = layers.GlobalAveragePooling2D(data_format='channels_last', keepdims = True)\n",
        "    self.flatten = layers.Flatten()\n",
        "    \n",
        "    self.classifier = tf.keras.Sequential([\n",
        "                                           layers.Dropout(dropout_rate),\n",
        "                                           layers.Dense(num_classes, activation = tf.keras.activations.sigmoid)\n",
        "                                          ])\n",
        "\n",
        "\n",
        "  def calculate_factors(self, version, alpha = 1.2, beta = 1.1):\n",
        "\n",
        "    phi, res, drop_rate = phi_values[version]\n",
        "    \n",
        "    depth_factor = alpha**phi\n",
        "    width_factor = beta**phi\n",
        "\n",
        "    return width_factor, depth_factor, drop_rate\n",
        "\n",
        "\n",
        "  def create_features(self, width_factor, depth_factor, last_channels):\n",
        "    channels = int(32*width_factor)\n",
        "    features = [CNNBlock(channels, kernel_size = 3, strides = 2, padding ='same')]\n",
        "    in_channels = channels\n",
        "\n",
        "    for expand_ratio, channels, repeats, stride, kernel_size in base_model:\n",
        "\n",
        "      out_channels = 4 * math.ceil(int(channels*width_factor)/4)\n",
        "      layer_repeats = math.ceil(repeats*depth_factor)\n",
        "\n",
        "      for layer in range(layer_repeats):\n",
        "\n",
        "        features.append(\n",
        "            InvertedResidualBlock(in_channels, \n",
        "                                  out_channels, \n",
        "                                  expand_ratio = expand_ratio,\n",
        "                                  strides = stride if layer == 0 else 1, \n",
        "                                  kernel_size = kernel_size, padding = 'same' )\n",
        "                                 )\n",
        "        \n",
        "        in_channels = out_channels\n",
        "      \n",
        "      features.append(\n",
        "          CNNBlock(last_channels, kernel_size = 1, strides = 1, padding ='same')\n",
        "      )\n",
        "\n",
        "      return tf.keras.Sequential(features)\n",
        "\n",
        "  def call(self, x):\n",
        "\n",
        "    x = self.pool(self.features(x))\n",
        "\n",
        "    x = self.flatten(x)\n",
        "\n",
        "    x = self.classifier(x)\n",
        "\n",
        "    return x    "
      ],
      "metadata": {
        "id": "DSBd8R4z-uT1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "-eHB8cIwjH1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version = 'b0'\n",
        "num_classes = 10"
      ],
      "metadata": {
        "id": "PYSPZiTcjPx-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phi, res, drop_rate = phi_values[version]"
      ],
      "metadata": {
        "id": "lo6QgHMnsNqd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientNet(\n",
        "    version = version,\n",
        "    num_classes = num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "veHrRcOgjJpo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.normal((3, res, res, 3))"
      ],
      "metadata": {
        "id": "IZ97E2W9jCEG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w-gvMHyrhv2",
        "outputId": "b10d6de5-0a9f-4371-cc4a-e1b54ffa6957"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 10)\n"
          ]
        }
      ]
    }
  ]
}